Jenkins -------->   Jenkins is an open-source automation server and continuous integration/continuous delivery (CI/CD) tool widely used in the software development industry. It provides a platform for automating various aspects of the software development lifecycle(SDLC), including building, testing, and deploying applications. 

Here are some key features and capabilities of Jenkins:

1.Automation: Jenkins allows you to automate tasks such as building code, running tests, deploying applications, and more. These tasks are defined as jobs or pipelines and can be triggered automatically based on various events, such as code commits, pull requests, or scheduled times.

2.Integration: Jenkins integrates with a wide range of development and deployment tools, including version control systems (e.g., Git, Subversion), build tools (e.g., Maven, Gradle), testing frameworks (e.g., JUnit, Selenium), and container orchestration platforms (e.g., Docker, Kubernetes).

3.Plugins: Jenkins has a vast ecosystem of plugins that extend its functionality. Plugins cover a wide range of areas, from source code management and build automation to deployment and notification. You can install and configure plugins to tailor Jenkins to your specific needs.

4.CI/CD: Jenkins is a core component of many CI/CD pipelines. It can automatically build and test code changes whenever they are committed to a version control system. Jenkins can also be used to automate the deployment of applications to various environments, from development and staging to production.

5.Pipeline as Code: Jenkins supports the definition of build and deployment pipelines as code using the Jenkinsfile format. This allows teams to version control their pipelines alongside their application code.

----------------------------------------------------------------------------------------------------
CI - CONTINOUS INTEGRATION (BUILD + TEST) = OLD CODE WITH NEW CODE
CD - CONTINOUS DELIVERY		: Deployment to production is manual
CD - CONTINOUS DEPLOYMET	: Deployment to production is automated



--------->  Continuous Integration (CI):

CI is the practice of automatically integrating code changes from multiple contributors into a shared repository, typically multiple times a day.
The primary goal of CI is to detect and address integration issues early in the development cycle, ensuring that the codebase is always in a working state.
CI pipelines automate tasks like code compilation, unit testing, and code analysis. When code is pushed to the repository, these tasks are automatically executed, and developers receive immediate feedback on the quality of their changes.

--------->  Continuous Delivery (CD):

CD extends the principles of CI to the deployment process. It focuses on automating the steps required to deliver a working and tested application to staging or production environments.

In a Continuous Delivery pipeline, the application is built, tested, and deployed to a staging environment automatically whenever new code is merged into the main branch. This allows for rapid and reliable staging of new features and bug fixes.

The key principle of CD is that every change to the codebase is potentially shippable to production. However, the decision to release to production is made manually.



--------->  Continuous Deployment (CD):

Continuous Deployment takes automation a step further. In a Continuous Deployment pipeline, every change that passes automated tests is automatically deployed to production without manual intervention.

--------------------------------------------------------------------------------------------------

ENV:
DEV	: DEVELOPERS
TEST	: TESTER
STAGING	: BEFORE PRODUCTION
UAT	: CLIENT
PROD	: USERS (LIVE)

PRE/NON PROD: DEV, TEST, UAT, STATING.
HIGH AVAILABILTY - MORE THAN ONE SERVER. (ONE -1A, TWO - 1B)

PIPELINE: 
SERIES OF EVENTS INTERNINKED WITH EACH OTHER.
STEP BY STEP EXECUTION OF A PROCESS.

-------------------------------------------------------------------------------------------------

JENKINS: PORT - 8080

SETUP:
STEP-1: GETTING REP0 (jenkins.io -- > downloads -- > Redhat)
sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key

STEP-2: INSTALLING JAVA 11
amazon-linux-extras install java-openjdk11 -y

STEP-3: INSTALLING GIT JENKINS MAVEN 
yum install git maven jenkins -y

STEP-4: STARTING THE SERVICE (any service will be on stopped state when its installed)
systemctl start jenkins
systemctl status jenkins

STEP-5: CONNECTING TO JENKINS
Public-ip:8080 -- > browser

---------------------------------------------------------------------------------------------------

CUSTOM WORKSPACE: it will gives the output on our desired location.

mkdir -p swiggy/jenkinsbuilds/
cd /root/swiggy/jenkinsbuilds

jenkins ui -- > jobname -- > configure -- > advance -- > custom workspace -- > /root/swiggy/jenkinsbuilds -- > save
chown jenkins:jenkins /root
chown jenkins:jenkins /root/*

CUSTOM WORKSPACE -------->  In the context of Jenkins, a custom workspace refers to a user-defined location where a Jenkins job or pipeline will store and manage its build artifacts, source code, and any other files needed during the build and deployment process. By specifying a custom workspace, you have more control over where these files are stored and can organize them according to your project's requirements.


pipeline {
    agent any
    options {
        // Define a custom workspace
        workspace(customWorkspace: '/path/to/custom/workspace')
    }
    stages {
        // Your build stages here
    }
}

-------------------------------------------------------------------------------------------------
--------->  Variables : In Jenkins, variables are used to store and manage data that can be used across different parts of your build and automation processes. 


Environment Variables:

Environment variables are system-level variables that can be accessed by Jenkins jobs and scripts. Jenkins automatically sets several environment variables, such as BUILD_NUMBER and WORKSPACE, that provide information about the build environment.
You can use environment variables in your Jenkins scripts to access information like the build number, build timestamp, or workspace directory.


Global Environment Variables (Jenkins Pipeline):

Jenkins Pipeline allows you to define global environment variables that are available to all stages and steps within the Pipeline.
These variables are defined using the environment block in your Jenkinsfile and can be used to set and access variables that persist across stages.


pipeline {
    agent any
    environment {
        CUSTOM_VARIABLE = 'Hello, Jenkins!'
    }
    stages {
        stage('Example') {
            steps {
                echo "Custom variable value: ${CUSTOM_VARIABLE}"
            }
        }
    }
}



VARIABLES: which will store the values & changes as per the time.

a. USER DEFINED VARS: 
1. LOCAL VARS: it will work inside a job

name=siva
loc=hyderabad
echo "hai all my name is $name, $name is comming from $loc"


2. GLOBAL VARS: it will work outside of a job
Dashboard -- > Manage Jenkins -- > System -- > Environment vars -- > add 

b. JENKINS ENVIRONMENT VARS: it can be defined by user

---------------------------------------------------------------------------------------------------

--------->  Parameters : In Jenkins, parameters are user-defined values that can be passed into a Jenkins job when it is executed. Parameters allow you to customize job runs, making your Jenkins jobs more flexible and versatile.

--------->  String Parameter:

A string parameter allows users to input a simple text value. This value can be used as an argument in your build scripts or as part of the job's configuration.
For example, you can use a string parameter to specify a version number, a file path, or a message.


--------->  Choice Parameter:

A choice parameter presents users with a predefined list of options from which they can select one. This is useful when you want users to choose from a set of known values.
For example, you can use a choice parameter to select a target environment (e.g., development, staging, production) or a build configuration (e.g., Debug, Release).


--------->  Boolean Parameter:

A boolean parameter allows users to toggle between two values: true or false. This is useful for jobs that have binary options or flags.
For example, you can use a boolean parameter to control whether a specific step in your job should be executed.


--------->  Password Parameter:

A password parameter is used to securely collect sensitive information, such as API keys or passwords. The input is hidden as asterisks to protect confidentiality.
This parameter is useful when you need to pass sensitive data to your job without displaying it in the Jenkins console log.


--------->  File Parameter:

A file parameter allows users to upload files to be used as input for the job. This can be helpful for jobs that require specific input files.
For example, you can use a file parameter to upload configuration files or data files needed for the build or deployment process.


--------->  Multi-line String Parameter:

A multi-line string parameter allows users to input multiple lines of text. This can be useful for jobs that require large blocks of text as input.
For example, you can use this parameter to collect release notes or commit messages.


--------->  Dynamic Choice Parameter (Scripted Pipeline):

In Jenkins Pipelines (Scripted Pipeline), you can create dynamic choice parameters that generate options based on Groovy scripts. This can be used to fetch options from external sources like APIs or databases.


--------->  Extended Choice Parameter (Plugin):

The "Extended Choice Parameter" plugin provides additional parameter types like radio buttons, checkboxes, and multiple-select boxes. It extends the built-in choice parameter functionality.

------------------------------------------------------------------------------------------------


--------->   Cron Syntax: The cron syntax consists of five fields (or six in some implementations), each representing a time unit:

Minute (0-59)
Hour (0-23)
Day of the month (1-31)
Month (1-12 or names like "Jan," "Feb")
Day of the week (0-6 or names like "Sun," "Mon")
(Optional) Year (usually not used in typical cron jobs)
Examples: Here are some examples of cron expressions:

0 2 * * *: Run the job at 2:00 AM every day.
0 0 * * 5: Run the job at midnight every Friday.
*/15 * * * *: Run the job every 15 minutes.
Common Usage: Cron jobs are commonly used for tasks like data backups, log rotation, periodic script execution, and scheduled maintenance.


CRONJOB: To schedule the works

*	: Minutes
*	: Hours
*	: Date
*	: Month
*	: day (0=sun)

9:00 am 23 : 0 9 23 6 5
10:30 pm 22: 30 22 22 6 4
----------------------------------------------------------------------------------------------
POLLSCM: It will set a time limit if the source code change on that time it will build.

WEBHOOKS: If the developer changes the code then it will build at that point of time.

THROTTLE BUILD: To restric the number of builds for time(M,H,D,W,M)

PASSWORDLESS LOGIN: 
cd /var/lib/jenkins
vim config.xml -- > line 7 : true=false -- > :wq
systemctl restart jenkins

------------------------------------------------------------------------------------------------

LINKED JOBS: one job is depending on another job.


PIPELINE: 
Series of events interlinked with each other.
Step-by-step execution of a process.

TYPES:
1. SCRIPTED
2. DECLARTIVE  -- > SHORTCUT: PASSS


examples:

pipeline {
    agent any 
    
    stages {
        stage('one') {
            steps {
                sh 'touch file1'
            }
        }
    }
}

-----------------------

pipeline {
    agent any 
    
    stages {
        stage('one') {
            steps {
                sh 'touch file1'
            }
        }
        stage('two') {
            steps {
                sh 'lscpu'
            }    
        }
    }
}

---------------------------

pipeline {
    agent any 
    
    stages {
        stage('one') {
            steps {
                sh 'touch file1'
            }
        }
        stage('two') {
            steps {
                sh 'lscpu'
            }    
        }
        stage('three') {
            steps {
                sh 'lsmem'
            }
        }
    }
}

----------------------------------------------------------------------------

PIPELINE AS A CODE: Executing mutiple actions on single stage.

pipeline {
    agent any 
    
    stages {
        stage('one') {
            steps {
                sh 'touch file1'
                sh 'lscpu'
                sh 'lsmem'
            }
        }
    }
}


PIPELINE AS A CODE ON MULTI STAGE:

pipeline {
    agent any 
    
    stages {
        stage('one') {
            steps {
                sh 'touch file1'
                sh 'lscpu'
                sh 'lsmem'
            }
        }
        stage('two') {
            steps {
                sh 'touch file2'
                sh 'free'
            }
        }
    }
}


--------->  A pipeline in the context of Jenkins refers to a continuous delivery (CD) pipeline or a continuous integration/continuous deployment (CI/CD) pipeline. It's a fundamental concept in Jenkins used to define and automate the stages and steps involved in building, testing, and deploying software applications. Jenkins Pipelines are typically defined as code and provide a structured way to express your software delivery process.

Here are the key components and concepts related to Jenkins Pipelines:

--------->  Pipeline Script: A Jenkins Pipeline is defined using a domain-specific language (DSL) that is either scripted or declarative. The choice between the two depends on your preferred syntax and complexity of your pipeline.

--------->  Scripted Pipeline: It's a more flexible and programmable way to define a pipeline using Groovy scripting. You have full control over the flow, but it can be more verbose.

--------->  Declarative Pipeline: This provides a more structured and simplified way to define a pipeline using a declarative syntax. It's easier to read and understand, especially for those not familiar with Groovy.

--------->  Stages: A Jenkins Pipeline consists of one or more stages, each representing a logical step in the software delivery process. Stages help break down the pipeline into manageable units, making it easier to visualize and understand the workflow.

--------->  Steps: Inside each stage, you define a series of steps to be executed. Steps can be commands, shell scripts, or function calls. They represent the actual work that needs to be done, such as compiling code, running tests, or deploying to a server.

--------->  Parallel Execution: Jenkins Pipelines support parallel execution, allowing you to execute multiple stages or steps concurrently, which can significantly improve build and deployment times.

--------->  Pipeline DSL: You can use a rich set of DSL (domain-specific language) functions and libraries provided by Jenkins to perform common tasks like checking out code from version control, archiving artifacts, sending notifications, and more.

--------->  Agent: You specify where the pipeline should be executed using an "agent" directive. An agent can be a specific Jenkins agent (node) or use the built-in "any" agent to run on any available node.

--------->  Integration: Jenkins Pipelines integrate seamlessly with a wide range of tools, including version control systems (e.g., Git), build tools (e.g., Maven, Gradle), testing frameworks (e.g., JUnit), container orchestration platforms (e.g., Docker, Kubernetes), and deployment platforms (e.g., AWS, Azure, Google Cloud).

--------->  Pipeline as Code: Jenkins Pipelines promote the concept of "pipeline as code," meaning that your entire software delivery process is versioned and stored alongside your application code in a version control system. This makes your pipeline easily maintainable, shareable, and reproducible.

Example of a simple declarative Jenkins Pipeline:

pipeline {
    agent any
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Build') {
            steps {
                sh 'make build'
            }
        }
        stage('Test') {
            steps {
                sh 'make test'
            }
        }
        stage('Deploy') {
            steps {
                sh 'make deploy'
            }
        }
    }
}

-------------------------------------------------------------------------------------------------

------------> Post Build Actions : In Jenkins, "Post-build Actions" are a set of configurable steps that you can specify to run after the primary build steps of a job have been completed. These actions are typically used to perform tasks such as archiving build artifacts, triggering downstream jobs, sending notifications, and more. Post-build actions allow you to extend the functionality of your Jenkins jobs and automate additional tasks that are important for your software development and deployment process.

------------------------------------------------------------------------------------------

POST-BUILD ACTIONS: the actions which comes after build.

1- always: it will execute all the time 

success cause:
pipeline {
    agent any
    
    stages {
        stage("one") {
            steps {
                echo "hai all"
            }
        }
    }
    post {
        always {
            echo "hello world"
        }
    }
}

failuer cause:
pipeline {
    agent any
    
    stages {
        stage("one") {
            steps {
                ech "hai all"
            }
        }
    }
    post {
        always {
            echo "hello world"
        }
    }
}


2-success: it will trigger if the build is success

success cause:

pipeline {
    agent any
    
    stages {
        stage("one") {
            steps {
                echo "hai all"
            }
        }
    }
    post {
        success {
            echo "hello world"
        }
    }
}

failuer cause:
pipeline {
    agent any
    
    stages {
        stage("one") {
            steps {
                ech "hai all"
            }
        }
    }
    post {
        always {
            echo "hello world"
        }
    }
}


3-failuer: 

pipeline {
    agent any
    
    stages {
        stage("one") {
            steps {
                echo "hai all"
            }
        }
    }
    post {
        failure {
            echo "hello world"
        }
    }
}

pipeline {
    agent any
    
    stages {
        stage("one") {
            steps {
                ech "hai all"
            }
        }
    }
    post {
        failure {
            echo "hello world"
        }
    }
}

--------------------------------------------------------------------------------------------------

INPUT PARAMETER:

pipeline {
    agent any

    stages {
        stage('checkout') {
            steps {
                git 'https://github.com/RAHAMSHAIK007/jenkins-java-project.git'
            }
        }
        stage('build') {
            steps {
                sh 'mvn compile'
            }
        }
        stage('test') {
            input {
                message 'can we test it'
                ok 'yes'
            }
            steps {
                sh 'mvn test'
            }
        }
        stage('artifact') {
            steps {
                sh 'mvn clean package'
            }
        }
    }
}


----------------------------------------------------------------------------------------

MASTER-SLAVE:
1. it will distribute the builds
2. it will reduce load on master
3. it will reduce the memory useage of master

CREATE A SERVER AND INSTALL JAVA-11
amazon-linux-extras install java-openjdk11 -y

Dashboard  Manage Jenkins Manage Nodes & clouds -- > New node -- > Name -- > Permanent Agent

Number of executors - no of builds paralelly (3)
Remote root directory - where your builds will be stored (/tmp)
Labels - assigning job to slave (swiggy)
Usage - last options
Launch method - last option
host - 172.31.82.90 (privateip)
Credentials -- > add -- > kind: ssh username with privatekey -- > username: ec2-usrer -- > privatekaey -- > add -- > pem -- > add -- > select ec2-user -- > Host Key Verification Strategy - last option


------------->  In the context of Jenkins, the terms "Master" and "Slave" refer to a distributed build and automation setup, where you have a central Jenkins server (Master) that manages and delegates tasks to one or more remote machines (Slaves) for executing jobs and tasks. This Master-Slave architecture in Jenkins is also known as the "Controller-Agent" or "Controller-Node" architecture.

Here's a breakdown of the roles and responsibilities of the Jenkins Master and Slaves:

Jenkins Master:

Control Center: The Jenkins Master serves as the central control center for managing all build and automation processes.

Job Configuration: It's responsible for storing and managing job configurations, including build scripts, parameters, and post-build actions.

Job Scheduling: The Master schedules jobs to be executed on available Jenkins Slaves. It decides which slave to use for each job based on the job's requirements and the availability of slaves.

User Interface: The Jenkins web interface is hosted on the Master. Users can create, configure, and trigger jobs through this interface.

Plugins: The Master hosts all installed Jenkins plugins, which provide additional functionality for various tasks like version control, build tools, deployment, and notifications.

Security and Access Control: It manages user authentication, authorization, and security settings for Jenkins.

Build Logs: The Master collects and stores build logs and job artifacts.

Jenkins Slaves (Agents or Nodes):

Build Execution: Jenkins Slaves are responsible for executing the actual build and automation tasks. Each Slave is a separate machine (physical or virtual) with its own resources.

Resource Isolation: Slaves provide resource isolation, allowing you to run different builds and jobs on different machines without resource conflicts.

Tools and Environments: Slaves can be configured with specific tools, libraries, and environments to match the requirements of the jobs they run.

Parallel Execution: Multiple Slaves can be used to execute jobs concurrently, which can significantly speed up the execution of a large number of jobs.

Platform Diversity: Slaves can run on different operating systems and architectures, allowing you to build and test software on various platforms.

How It Works:

When a job is triggered on the Jenkins Master, the Master schedules it for execution.

The Master selects an available Jenkins Slave based on criteria such as labels, resource availability, and configured job requirements.

The job is sent to the selected Slave for execution.

The Slave performs the build or automation tasks based on the job's configuration.

Build logs and artifacts are generated on the Slave and sent back to the Master for storage and display in the Jenkins interface.

Once the job is complete, the Slave becomes available for other jobs.

Use Cases:

The Master-Slave architecture is especially valuable when you have a high volume of build and automation tasks, and you want to distribute the workload across multiple machines to improve efficiency.

It's useful for running builds and tests on different platforms or in isolated environments.

You can use Jenkins Slaves to scale your Jenkins infrastructure as your organization's needs grow.

Overall, the Master-Slave architecture in Jenkins allows you to build and automate software efficiently by distributing tasks across multiple machines while centralizing management and control on the Jenkins Master.

--------------------------------------------------------------------------------------------------

RBAC	: ROLE BASED ACCESS CONTROL
To restrict the jenkins Control for the users.
authentication - who can signin
authorization - who can work

user-1: EXP (rajesh)           user-2:FRESHER (raju)	USER-3: FRESHER

1. USERS: Dashboard -- > Manage Jenkins -- > security -- > Users (crearte 2 users)
2. PLUGIN: Dashboard -- > Manage Jenkins -- > Plugins -- > Available plugins -- > Role-based Authorization Strategy  -- > install -- > goback to top
3. Dashboard  -- > Manage Jenkins -- > Security -- > Authorization: Role-Based strategy
4. ROLES : Dashboard  -- > Manage Jenkins -- > Security -- > Manage and Assign Roles -- >
   create Fresher & Experience roles and give permissions(EXP: ADMIN, FRE: BUILD AND READ)
5. ASSIGN ROLES: user-1: EXP           user-2:FRESHER



RBAC stands for Role-Based Access Control, and it's a method of controlling and managing access to computer systems or resources based on roles and permissions. RBAC is widely used in various IT environments, including operating systems, databases, and applications, to ensure that users and entities have the appropriate level of access to perform their tasks while maintaining security and least privilege principles.

In RBAC, access control is organized around the following key concepts:

Roles: Roles are sets of permissions or access rights that define what actions or operations a user or entity is allowed to perform within a system or application. Roles are usually defined based on job responsibilities or functions, and each role corresponds to a specific set of permissions.

Permissions: Permissions are fine-grained access rights or privileges that define specific actions or operations that can be performed on a resource or within a system. For example, permissions can include read, write, execute, create, delete, or modify access.

Users and Entities: Users, entities, or subjects are individuals, groups, or software components (e.g., applications or services) that interact with a system. Each user or entity is assigned one or more roles that determine their access rights.

Resources: Resources are the objects, data, or components within a system that are protected by RBAC. Resources can include files, databases, network services, or any other asset that requires access control.

RBAC operates on the principle of least privilege, meaning that users or entities are granted only the permissions necessary to perform their job functions, reducing the risk of unauthorized access or misuse of resources. RBAC helps organizations enforce security policies, improve access management, and simplify the administration of access control.

Here's how RBAC typically works:

Role Assignment: Users or entities are assigned to one or more roles based on their job responsibilities or functional requirements. For example, a database administrator might be assigned the "Database Administrator" role, while a software developer might be assigned the "Developer" role.

Role Permissions: Each role is associated with a set of permissions or access rights that define what actions the role can perform. These permissions are typically defined in a centralized access control policy.

Access Control Policy: The access control policy specifies which roles have access to specific resources and what actions they can perform on those resources. The policy is enforced by the system or application.

Access Request: When a user or entity attempts to access a resource or perform an action, the system checks their role and verifies that the role has the necessary permissions. If the user's role has the required permissions, access is granted; otherwise, access is denied.

Role Changes: As users' job roles change or evolve, their role assignments can be modified to reflect their new responsibilities. This ensures that users always have the appropriate level of access.

RBAC is a fundamental concept in access control and security management, and it plays a crucial role in safeguarding sensitive data and resources in a wide range of IT environments, including cloud services, databases, network systems, and software applications. It provides a structured and efficient approach to access management and helps organizations maintain security and compliance.


==============================================================================
LIST VIEW: USED TO SEPERATE/FILTER THE JOBS.
MY VIEW: USED TO SHOW THE JOBS WHICH I HAVE PERMISSIONS.
BUILD PIPELINE VIEW: To show the process of linked jobs -- > PLUGINS -- > AVAILABLE -- > Build Pipeline -- > INSTALL
